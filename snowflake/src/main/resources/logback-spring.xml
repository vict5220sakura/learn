<?xml version="1.0" encoding="UTF-8"?>
<configuration>

    <property name="LOG_PATH" value="${user.dir}/logs/bithaw/zbt" />
	
	
    <!-- 文件输出格式 -->
    <property name="PATTERN"
              value="%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger [%file:%line] - %msg%n"/>

    <property name="BASE_FILE_PATH" value="${LOG_PATH}"/>
    <property name="INFO_FILE_PATH" value="${LOG_PATH}/info"/>
    <property name="WARN_FILE_PATH" value="${LOG_PATH}/warn"/>
    <property name="ERROR_FILE_PATH" value="${LOG_PATH}/error"/>

    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger [%file:%line] - %msg%n</pattern>
        </encoder>
    </appender>

    <appender name="INFO-APPENDER" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 文件路径 -->
        <file>${BASE_FILE_PATH}/info.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 文件名称 -->
            <fileNamePattern>${INFO_FILE_PATH}/info.%d{yyyy-MM-dd}.%i.gz</fileNamePattern>
            <!-- 文件最大保存历史数量 -->
            <maxHistory>100000</maxHistory>
            <!-- 日志文件rolling触发策略 -->
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <MaxFileSize>10MB</MaxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>

        <encoder>
            <pattern>${PATTERN}</pattern>
            <charset>UTF-8</charset> <!-- 此处设置字符集 -->
        </encoder>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <appender name="WARN-APPENDER" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 文件路径 -->
        <file>${BASE_FILE_PATH}/warn.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 文件名称 -->
            <fileNamePattern>${WARN_FILE_PATH}/warn.%d{yyyy-MM-dd}.%i.gz</fileNamePattern>
            <!-- 文件最大保存历史数量 -->
            <maxHistory>100000</maxHistory>
            <!-- 日志文件rolling触发策略 -->
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <MaxFileSize>10MB</MaxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>

        <encoder>
            <pattern>${PATTERN}</pattern>
            <charset>UTF-8</charset> <!-- 此处设置字符集 -->
        </encoder>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>WARN</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <appender name="ERROR-APPENDER" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 文件路径 -->
        <file>${BASE_FILE_PATH}/error.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 文件名称 -->
            <fileNamePattern>${ERROR_FILE_PATH}/error.%d{yyyy-MM-dd}.%i.gz</fileNamePattern>
            <!-- 文件最大保存历史数量 -->
            <maxHistory>100000</maxHistory>
            <!-- 日志文件rolling触发策略 -->
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <MaxFileSize>10MB</MaxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>

        <encoder>
            <pattern>${PATTERN}</pattern>
            <charset>UTF-8</charset> <!-- 此处设置字符集 -->
        </encoder>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>
    
    <!-- kafka输出 -->
<!-- 	<appender name="KafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
	    <encoder class="com.github.danielwegener.logback.kafka.encoding.LayoutKafkaMessageEncoder">
	        <layout class="net.logstash.logback.layout.LogstashLayout" >
	            <includeContext>true</includeContext>
	            <includeCallerData>true</includeCallerData>
	            <customFields>{"system":"order-service"}</customFields>
	            <fieldNames class="net.logstash.logback.fieldnames.ShortenedFieldNames"/>
	        </layout>
	        <charset>UTF-8</charset>
	    </encoder>
	    kafka topic 需要与配置文件里面的topic一致 否则kafka会沉默并鄙视你
	    <topic>hlg</topic>
	    <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.HostNameKeyingStrategy" />
	    <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
	    <producerConfig>bootstrap.servers=106.15.95.180:9092</producerConfig>
	</appender>
    
    <logger name="com.bithaw.zbt" level="ERROR">
    	<appender-ref ref="KafkaAppender" />
    </logger>
    
    <logger name="com.bithaw.zbt" level="INFO">
    	<appender-ref ref="KafkaAppender" />
    </logger> -->

    <root level="info">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="INFO-APPENDER"/>
        <appender-ref ref="WARN-APPENDER"/>
        <appender-ref ref="ERROR-APPENDER"/>
    </root>

</configuration>